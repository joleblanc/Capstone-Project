---
title: "Capstone Project"
author: "Johannes Le Blanc"
date: "22 Januar 2019"
output: html_document
---

```{r setup, include=FALSE}
library(dslabs)
library(tidyverse)
library(tibble)
library(dplyr)
library(tidyr)
library(devtools)
library(ggplot2)
library(statsr)
library(ggrepel)
library(SLICER)
library(stringr)
library(htmlwidgets)
library(purrr)
library(lubridate)
library(ggthemes)
library(bindrcpp)
library(gridExtra)
library(MASS)
library(caret)
library(purrr)
library(randomForest)
library(e1071)
library(rpart)
knitr::opts_chunk$set(echo = TRUE)
```

## Loading the data and creating the train and test set.

```{r, message=FALSE}
#############################################################
# Create edx set, validation set, and submission file
#############################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- read.table(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                      col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data

set.seed(1)
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set

validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set

removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
```

## Part1 -  Quiz: MovieLens Dataset

1. How many rows and columns are there in the edx dataset?
  
  ```{r pressure, echo=FALSE}
dim(edx)
```


2.a How many zeros were given as ratings in the edx dataset?
  
  ```{r}
edx %>% filter(rating == 0) %>% tally()
```

2.b How many threes were given as ratings in the edx dataset?
  
  ```{r}
edx %>% filter(rating == 3) %>% tally()
```


3. How many different movies are in the edx dataset?
  
  ```{r}
n_distinct(edx$movieId)
```

4. How many different users are in the edx dataset?
  
  ```{r}
n_distinct(edx$userId)
```

5. How many movie ratings are in each of the following genres in the edx dataset?
  
  ```{r}
edx %>% separate_rows(genres, sep = "\\|") %>%
  group_by(genres) %>%
  summarize(count = n()) %>%
  arrange(desc(count))
```


6. Which movie has the greatest number of ratings?
  
  ```{r}
edx %>% group_by(movieId, title) %>%
  summarize(count = n()) %>%
  arrange(desc(count))
```

7. What are the five most given ratings in order from most to least?
  
  ```{r}
edx %>% group_by(rating) %>% summarize(count = n()) %>% top_n(5) %>%
  arrange(desc(count)) 
```

8. True or False: In general, half star ratings are less common than whole star ratings (e.g., there are fewer ratings of 3.5 than there are ratings of 3 or 4, etc.).

TRUE

## Part 2 - Predicted movie ratings and RMSE

### The first naive model

```{r}
mu_hat <- mean(edx$rating)
mu_hat
```

Naive RMSE

```{r}
naive_rmse <- RMSE(validation$rating, mu_hat)
naive_rmse
```

Results table for the naive approach

```{r}
rmse_results <- data_frame(method = "Just the average", RMSE = naive_rmse)
```

Modeling estimates of movie effects

```{r}
mu <- mean(edx$rating) 
movie_avgs <- edx %>% 
  group_by(movieId) %>% 
  summarize(b_i = mean(rating - mu))
```

Plot of estimates

```{r}
movie_avgs %>% qplot(b_i, geom ="histogram", bins = 30, data = ., color = I("black"))
```

New prediction to show the difference to the naive approach

```{r}
predicted_ratings <- mu + validation %>% 
  left_join(movie_avgs, by='movieId') %>%
  .$b_i

model_1_rmse <- RMSE(predicted_ratings, validation$rating)
rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Movie Effect Model",  
                                     RMSE = model_1_rmse ))
rmse_results %>% knitr::kable()
```

Modeling user effect to get the average rating for the user
```{r}
edx %>% 
  group_by(userId) %>% 
  summarize(b_u = mean(rating)) %>% 
  filter(n()>=100) %>%
  ggplot(aes(b_u)) + 
  geom_histogram(bins = 30, color = "black")
```

Compute approximation of user effects
```{r}
user_avgs <- validation %>% 
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu - b_i))
```

Create predictors to show improvement of RMSE
```{r}
predicted_ratings <- validation %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  mutate(pred = mu + b_i + b_u) %>%
  .$pred


model_2_rmse <- RMSE(predicted_ratings, validation$rating)
rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Movie + User Effects Model",  
                                     RMSE = model_2_rmse ))
rmse_results %>% knitr::kable()
```

# PART 3

##Improve results to get a lower RMSE

Check for the 10 largest mistakes to improve the model

```{r}
validation %>% 
  left_join(movie_avgs, by="movieId") %>%
  mutate(residual = rating - (mu + b_i)) %>%
  arrange(desc(abs(residual))) %>% 
  dplyr::select(title, residual) %>% slice(1:10) %>% knitr::kable()
```

Connect movieID with titles

```{r}
movie_titles <- movielens %>% 
  dplyr::select(movieId, title) %>%
  distinct()
```


List of the 10 best movies without correcting for number of ratings

```{r}
movie_avgs %>% left_join(movie_titles, by="movieId") %>%
  arrange(desc(b_i)) %>% 
  dplyr::select(title, b_i) %>% 
  slice(1:10) %>%   knitr::kable() 
```


List of the 10 worst movies without correcting for number of ratings

```{r}
movie_avgs %>% left_join(movie_titles, by="movieId") %>%
  arrange(b_i) %>% 
  dplyr::select(title, b_i) %>% 
  slice(1:10) %>%  
  knitr::kable()
```


How often are the best movies rated 

```{r}
edx %>% count(movieId) %>% 
  left_join(movie_avgs) %>%
  left_join(movie_titles, by="movieId") %>%
  arrange(desc(b_i)) %>% 
  dplyr::select(title, b_i, n) %>% 
  slice(1:10) %>% 
  knitr::kable()
```


How often are the worst movies rated

```{r}
edx %>% count(movieId) %>% 
  left_join(movie_avgs) %>%
  left_join(movie_titles, by="movieId") %>%
  arrange(b_i) %>% 
  dplyr::select(title, b_i, n) %>% 
  slice(1:10) %>% 
  knitr::kable()
```


Regularized estimates: exclude movies with less than 5 ratings

```{r}
lambda <- 5
mu <- mean(edx$rating)
movie_reg_avgs <- edx %>% 
  group_by(movieId) %>% 
  summarize(b_i = sum(rating - mu)/(n()+lambda), n_i = n()) 
```


Plot of regularization to show regularized estimates vs. least square estimates

```{r}
data_frame(original = movie_avgs$b_i, 
           regularlized = movie_reg_avgs$b_i, 
           n = movie_reg_avgs$n_i) %>%
  ggplot(aes(original, regularlized, size=sqrt(n))) + 
  geom_point(shape=1, alpha=0.5)
```


Top 10 movies based on lambda

```{r}
edx %>%
  count(movieId) %>% 
  left_join(movie_reg_avgs) %>%
  left_join(movie_titles, by="movieId") %>%
  arrange(desc(b_i)) %>% 
  dplyr::select(title, b_i, n) %>% 
  slice(1:10) %>% 
  knitr::kable()
```


10 worst movies based on lambda

```{r}
edx %>%
  count(movieId) %>% 
  left_join(movie_reg_avgs) %>%
  left_join(movie_titles, by="movieId") %>%
  arrange(b_i) %>% 
  dplyr::select(title, b_i, n) %>% 
  slice(1:10) %>% 
  knitr::kable()
```

Show change of results compared to previous estimates of RMSE

```{r}
predicted_ratings <- validation %>% 
  left_join(movie_reg_avgs, by='movieId') %>%
  mutate(pred = mu + b_i) %>%
  .$pred

model_3_rmse <- RMSE(predicted_ratings, validation$rating)
rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Regularized Movie Effect Model",  
                                     RMSE = model_2_rmse ))
rmse_results %>% knitr::kable()
```


Choose lambda

```{r}
lambdas <- seq(0, 10, 0.25)

mu <- mean(edx$rating)
just_the_sum <- edx %>% 
  group_by(movieId) %>% 
  summarize(s = sum(rating - mu), n_i = n())

rmses <- sapply(lambdas, function(l){
  predicted_ratings <- validation %>% 
    left_join(just_the_sum, by='movieId') %>% 
    mutate(b_i = s/(n_i+l)) %>%
    mutate(pred = mu + b_i) %>%
    .$pred
  return(RMSE(predicted_ratings, validation$rating))
})
qplot(lambdas, rmses)  
lambdas[which.min(rmses)]
```


Pick lambda with cross-validation 

```{r}
lambdas <- seq(0, 10, 0.25)

rmses <- sapply(lambdas, function(l){
  
  mu <- mean(edx$rating)
  
  b_i <- edx %>% 
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n()+l))
  
  b_u <- edx %>% 
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mu)/(n()+l))
  
  predicted_ratings <- 
    validation %>% 
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    mutate(pred = mu + b_i + b_u) %>%
    .$pred
  
  return(RMSE(predicted_ratings, validation$rating))
})

qplot(lambdas, rmses) 
```
 

Calculate the optimal lambda for the whole model 

```{r}
lambda <- lambdas[which.min(rmses)]
lambda
```


Create table to show results of the model and the different results of RSME

```{r}
rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Regularized Movie + User Effect Model",  
                                     RMSE = min(rmses)))
rmse_results %>% knitr::kable()
```
